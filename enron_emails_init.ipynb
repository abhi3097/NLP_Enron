{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os, sys\n",
    "import collections\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import email\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import random\n",
    "\n",
    "# Helper libraries\n",
    "import constants\n",
    "import utils\n",
    "import vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Email Bodies\n",
    "Data source and exploration code: [Kaggle](https://www.kaggle.com/zichen/explore-enron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 2)\n",
      "Message-ID: <15464986.1075855378456.JavaMail.evans@thyme>\n",
      "Date: Fri, 4 May 2001 13:51:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: john.lavorato@enron.com\n",
      "Subject: Re:\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: John J Lavorato <John J Lavorato/ENRON@enronXgate@ENRON>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen (Non-Privileged).pst\n",
      "\n",
      "Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\n",
      "\n",
      "As far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \n",
      "\n",
      "My suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load csv dataset - download from Kaggle (linked above, ~.5gb)\n",
    "\n",
    "# replace with local path\n",
    "path = 'C:/Users/Colby/Documents/Berkeley/266_NLP/final_project/data'\n",
    "\n",
    "#emails_df = pd.read_csv(path + '/emails.csv')\n",
    "emails_df = pd.read_csv(path + '/emails.csv', nrows=2000)\n",
    "\n",
    "print(\"Shape:\", emails_df.shape)\n",
    "emails_df.head()\n",
    "print(emails_df['message'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  \\\n",
       "0     allen-p/_sent_mail/1.   \n",
       "1    allen-p/_sent_mail/10.   \n",
       "2   allen-p/_sent_mail/100.   \n",
       "3  allen-p/_sent_mail/1000.   \n",
       "4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
       "\n",
       "                                         content_str  \n",
       "0                          Here is our forecast\\n\\n   \n",
       "1  Traveling to have a business meeting takes the...  \n",
       "2                     test successful.  way to go!!!  \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...  \n",
       "4                Let's shoot for Tuesday at 11:45.    "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# citation: Kaggle exploration code\n",
    "# isolate email body\n",
    "\n",
    "def get_text_from_email(msg):\n",
    "    '''To get the content from email objects'''\n",
    "    parts = []\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            parts.append( part.get_payload() )\n",
    "    return ''.join(parts)\n",
    "\n",
    "# Parse the emails into a list email objects\n",
    "messages = list(map(email.message_from_string, emails_df['message']))\n",
    "#emails_df.drop('message', axis=1, inplace=True)\n",
    "\n",
    "# Parse content from emails\n",
    "emails_df['content_str'] = list(map(get_text_from_email, messages))\n",
    "\n",
    "del messages\n",
    "\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Email Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445556\n"
     ]
    }
   ],
   "source": [
    "# tokenize and canonicalize each email to get vocab\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "all_tokens = []\n",
    "email_tokens = []\n",
    "\n",
    "for i, body in enumerate(emails_df[\"content_str\"]):\n",
    "    #get sentence level\n",
    "    sents = nltk.tokenize.sent_tokenize(body)\n",
    "    canon = []\n",
    "    for sent in sents:\n",
    "        #list of tokens in sentence\n",
    "        sent_tokens = tokenizer.tokenize(sent)\n",
    "        canon += utils.canonicalize_words(sent_tokens)\n",
    "    all_tokens += canon\n",
    "    email_tokens.append(canon)\n",
    "\n",
    "emails_df[\"content_tokens\"] = email_tokens\n",
    "print(len(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 500\n",
      "Unigrams:  16832\n"
     ]
    }
   ],
   "source": [
    "# build vocab\n",
    "# V = size\n",
    "V = 500\n",
    "vocab = vocabulary.Vocabulary(all_tokens, size=V)\n",
    "print(\"Vocabulary size: {:,}\".format(vocab.size))\n",
    "vocab_ids = vocab.words_to_ids(all_words)\n",
    "print(\"Unigrams: \", len(vocab.unigram_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 2, 5, 1, 0, 414, 7, 203, 75, 75, 1, 0, 75, 1]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess email bodies with unknowns and sentence buffers\n",
    "emails_preprocessed = []\n",
    "\n",
    "for i, body in enumerate(emails_df[\"content_str\"]):\n",
    "    #get sentence level\n",
    "    sents = nltk.tokenize.sent_tokenize(body)\n",
    "    list_sents = []\n",
    "    for sent in sents:\n",
    "        #list of tokens in sentence\n",
    "        sent_tokens = tokenizer.tokenize(sent)\n",
    "        list_sents.append(sent_tokens)\n",
    "    #preprocessed = list(utils.preprocess_sentences(list_sents, vocab, use_eos=True, emit_ids=False))\n",
    "    #just keep word IDs\n",
    "    preprocessed = list(utils.preprocess_sentences(list_sents, vocab, use_eos=True, emit_ids=True))\n",
    "    emails_preprocessed.append(preprocessed)\n",
    "\n",
    "emails_df[\"content_IDS\"] = emails_preprocessed\n",
    "emails_preprocessed[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '.',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'way',\n",
       " 'to',\n",
       " 'go',\n",
       " '!',\n",
       " '!',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '!',\n",
       " '</s>']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test ID to word\n",
    "vocab.ids_to_words(emails_df[\"content_IDS\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "      <th>content_tokens</th>\n",
       "      <th>content_IDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>[here, is, our, forecast]</td>\n",
       "      <td>[0, 93, 18, 89, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>[traveling, to, have, a, business, meeting, ta...</td>\n",
       "      <td>[0, 2, 7, 39, 12, 266, 133, 2, 6, 2, 96, 11, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>[test, successful, ., way, to, go, !, !, !]</td>\n",
       "      <td>[0, 2, 2, 5, 1, 0, 414, 7, 203, 75, 75, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>[randy, ,, can, you, send, me, a, schedule, of...</td>\n",
       "      <td>[0, 2, 4, 66, 13, 216, 84, 12, 2, 11, 6, 2, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>[let, 's, shoot, for, tuesday, at, DGDG:DGDG, .]</td>\n",
       "      <td>[0, 151, 56, 2, 14, 467, 35, 51, 5, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  \\\n",
       "0     allen-p/_sent_mail/1.   \n",
       "1    allen-p/_sent_mail/10.   \n",
       "2   allen-p/_sent_mail/100.   \n",
       "3  allen-p/_sent_mail/1000.   \n",
       "4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
       "\n",
       "                                         content_str  \\\n",
       "0                          Here is our forecast\\n\\n    \n",
       "1  Traveling to have a business meeting takes the...   \n",
       "2                     test successful.  way to go!!!   \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...   \n",
       "4                Let's shoot for Tuesday at 11:45.     \n",
       "\n",
       "                                      content_tokens  \\\n",
       "0                          [here, is, our, forecast]   \n",
       "1  [traveling, to, have, a, business, meeting, ta...   \n",
       "2        [test, successful, ., way, to, go, !, !, !]   \n",
       "3  [randy, ,, can, you, send, me, a, schedule, of...   \n",
       "4   [let, 's, shoot, for, tuesday, at, DGDG:DGDG, .]   \n",
       "\n",
       "                                         content_IDS  \n",
       "0                              [0, 93, 18, 89, 2, 1]  \n",
       "1  [0, 2, 7, 39, 12, 266, 133, 2, 6, 2, 96, 11, 6...  \n",
       "2  [0, 2, 2, 5, 1, 0, 414, 7, 203, 75, 75, 1, 0, ...  \n",
       "3  [0, 2, 4, 66, 13, 216, 84, 12, 2, 11, 6, 2, 10...  \n",
       "4             [0, 151, 56, 2, 14, 467, 35, 51, 5, 1]  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sparse matrix of word ID feature\n",
    "x_sparse = utils.id_lists_to_sparse_bow(emails_df[\"content_IDS\"], vocab.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Random Sample for Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1458, 784, 1719, 1193, 373, 447, 342, 397, 346, 1373, 1396, 187, 1445, 1551, 309, 1651, 1447, 580, 1483, 1888, 1568, 26, 903, 957, 1773, 1476, 1300, 236, 57, 1058, 345, 1962, 1006, 1513, 1731, 909, 623, 1023, 1951, 174, 1407, 1557, 520, 1726, 1252, 322, 1395, 669, 1966, 625, 152, 1110, 1329, 751, 1353, 1830, 68, 1893, 437, 647, 694, 1832, 1521, 142, 636, 198, 503, 1362, 1221, 1636, 313, 1677, 1736, 1002, 1760, 581, 545, 1151, 560, 405, 191, 1180, 1012, 1607, 315, 1336, 293, 664, 982, 1372, 1237, 1994, 1604, 269, 974, 1035, 531, 1042, 1566, 462]\n",
      "(100, 5)\n",
      "Message-ID: <14134673.1075855725697.JavaMail.evans@thyme>\n",
      "Date: Mon, 19 Mar 2001 01:36:00 -0800 (PST)\n",
      "From: phillip.allen@enron.com\n",
      "To: jacquestc@aol.com\n",
      "Subject: \n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: jacquestc@aol.com\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_June2001\\Notes Folders\\'sent mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen.nsf\n",
      "\n",
      "Jacques,\n",
      "\n",
      "Still trying to close the loop on the $15,000 of extensions.  Assuming that \n",
      "it is worked out today or tomorrow, I would like to get whatever documents \n",
      "need to be\n",
      "completed to convey the partnership done.  I need to work with the engineer \n",
      "and architect to get things moving.  I am planning on  writing a personal \n",
      "check to the engineer while I am setting up new accounts.  Let me know if \n",
      "there is a reason I should not do this.\n",
      "\n",
      "Thanks for all your help so far.  Between your connections and expertise in \n",
      "structuring the loan, you saved us from getting into a bad deal.\n",
      "\n",
      "Phillip\n"
     ]
    }
   ],
   "source": [
    "random.seed(24)\n",
    "rand_ids = random.sample(range(2000), 100)\n",
    "print(rand_ids)\n",
    "train_set = emails_df.loc[rand_ids,]\n",
    "print(train_set.shape)\n",
    "print(train_set['message'][373])\n",
    "label_dict = {373: 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".....\n",
    "\n",
    "# From Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting IDs to a feature vector\n",
    "\n",
    "Many NLP models are designed to work directly with a sequence of word ids. However, for many standard machine learning models such as Naive Bayes, SVMs, or Logistic Regression, we need to convert this sequence to a fixed-length vector $x \\in \\mathbb{R}^d$. In the general case, we can define a set of feature extractors $f_i$ for $i = 0,1,\\ldots,d-1$, such that $x_i = f_i([\\mathtt{ids}])$.\n",
    "\n",
    "The simplest way to do this is a bag-of-words model, in which we let the number of features be the size of our vocabulary ($d = |V|$), and we let each feature be a count of the number of times word $i$ appears in the sequence:\n",
    "\n",
    "$$ f_i([\\mathtt{ids}]) = \\sum_{j = 0}^{n} \\mathbf{1}[w_j = i] $$\n",
    "\n",
    "We can do this in a very simple way by using the `collections.Counter` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Example, with words as keys:\", collections.Counter(x_tokens_canonical))\n",
    "x_fdict = collections.Counter(x_ids)\n",
    "x_fdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common data format to use in machine learning applications is to transform this dictionary-like object that maps keys to values into a feature vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = vocab.size  # one feature for each word\n",
    "x_vector = [x_fdict.get(i, 0) for i in range(num_features)]\n",
    "x_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one has multiple examples, these are represented as multiple rows of these vectors stacked on top of one another (similar to the batching you did in assignment 1).  If $|V|$ is large and the text short, it is likely most of the elements of such a matrix are zero.  A memory optimization can be made by using a [sparse vector](https://docs.scipy.org/doc/scipy/reference/sparse.html) representation. (Or for more than one example, a sparse matrix.) You may have worked with these before, as they are the preferred input format for many `scikit-learn` ML routines.\n",
    "\n",
    "The sparse matrix constructor requires three parallel lists: the row indices, the column indices, and the corresponding values.  Note that we have just a single row (we have only one example), so all the row indices are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  See https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix\n",
    "from scipy.sparse import csr_matrix \n",
    "\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "values = []\n",
    "\n",
    "# Construct three parallel lists as described above to satisfy the sparse matrix constructor.\n",
    "for wordid, count in x_fdict.items():\n",
    "    row_indices.append(0)       # only a single example, so row 0\n",
    "    col_indices.append(wordid)  # column is word id\n",
    "    values.append(count)        # value is count\n",
    "x_sparse = csr_matrix((values, (row_indices, col_indices)),\n",
    "                      shape=[1, vocab.size])\n",
    "print(\"Non-zero values:\")\n",
    "print(x_sparse)\n",
    "x_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided a helper function, `utils.id_lists_to_sparse_bow` that can handle this conversion over a whole dataset, and in most cases we'll handle this conversion for you in the starter code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
