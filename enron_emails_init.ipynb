{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os, sys\n",
    "import collections\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import email\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import *\n",
    "import random\n",
    "\n",
    "# Helper libraries\n",
    "import constants\n",
    "import utils\n",
    "import vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Email Bodies\n",
    "Data source and exploration code: [Kaggle](https://www.kaggle.com/zichen/explore-enron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (517401, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv dataset - download from Kaggle (linked above, ~.5gb)\n",
    "\n",
    "# replace with local path\n",
    "path = 'C:/Users/Colby/Documents/Berkeley/266_NLP/final_project/data'\n",
    "\n",
    "# all emails for targeted search\n",
    "all_emails = pd.read_csv(path + '/emails.csv')\n",
    "#emails_df = pd.read_csv(path + '/emails.csv', rows = 50000)\n",
    "\n",
    "print(\"Shape:\", all_emails.shape)\n",
    "all_emails.head()\n",
    "#print(all_emails['message'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full shape: (517401, 3)\n",
      "Mini shape: (50000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  \\\n",
       "0     allen-p/_sent_mail/1.   \n",
       "1    allen-p/_sent_mail/10.   \n",
       "2   allen-p/_sent_mail/100.   \n",
       "3  allen-p/_sent_mail/1000.   \n",
       "4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
       "\n",
       "                                         content_str  \n",
       "0                          Here is our forecast\\n\\n   \n",
       "1  Traveling to have a business meeting takes the...  \n",
       "2                     test successful.  way to go!!!  \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...  \n",
       "4                Let's shoot for Tuesday at 11:45.    "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# citation: Kaggle exploration code\n",
    "# isolate email body\n",
    "# run-time: ~ 3 minutes on full dataset\n",
    "\n",
    "def get_text_from_email(msg):\n",
    "    '''To get the content from email objects'''\n",
    "    parts = []\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            parts.append( part.get_payload() )\n",
    "    return ''.join(parts)\n",
    "\n",
    "# Parse the emails into a list email objects\n",
    "messages = list(map(email.message_from_string, all_emails['message']))\n",
    "#emails_df.drop('message', axis=1, inplace=True)\n",
    "\n",
    "# Parse content from emails\n",
    "all_emails['content_str'] = list(map(get_text_from_email, messages))\n",
    "\n",
    "del messages\n",
    "\n",
    "\n",
    "# mini version for preprocessing (to save run-time)\n",
    "size = 50000\n",
    "emails_df = all_emails.loc[range(size),]\n",
    "print(\"Full shape:\", all_emails.shape)\n",
    "print(\"Mini shape:\", emails_df.shape)\n",
    "\n",
    "all_emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Raw Contents for Suspicious Phrases\n",
    "### Store dataframe indexes\n",
    "Use this block to search raw messages and store the row indexes in *target_ids*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n",
      "Matching indexes: [6754, 261945, 325261, 450200, 453212]\n"
     ]
    }
   ],
   "source": [
    "# test phrase - enter between quotes\n",
    "phrase = \"keep this quiet\"\n",
    "\n",
    "query = all_emails[all_emails['content_str'].str.contains(phrase, case=False)]\n",
    "print(query.shape)\n",
    "print(\"Matching indexes:\", query.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suzanne:\n",
      "Everything is fine although I am really looking forward to spending more time \n",
      "out of the house.  I think that Bill and I need some space as well.  Can you \n",
      "sense that I am getting restless already?  I am really going to try hard to \n",
      "stay in contact with you and others there because I have discovered that \n",
      "talking to you and the others on the phone or by e-mail gives me a lift.  \n",
      "Charles is doing well.  I am a little frustrated with the schedule that we \n",
      "are on which seems to vary from day to day but hopefully things will approach \n",
      "normalcy in a few weeks.  we met our new pediatrician this past week and we \n",
      "both really like him.  Charles checked out fine.  He had gained over a pound \n",
      "since leaving the hospital so I am happy that he appears to be getting enough \n",
      "to eat.  My parents and sister are coming around Sept. 23rd for the \n",
      "christening and I am looking forward to that.  Please mark your calendar for \n",
      "that Sunday as I think that we will have something at the house and I very \n",
      "much want you and Ric to come and meet everyone.\n",
      "\n",
      "Alos, if people want to visit me here at the house ask them to call me.  I \n",
      "would very much like to see them if they want to stop by.\n",
      "\n",
      "I can't believe that I actually miss work but I do.  Hopefully, in a few \n",
      "weeks I acn make some type of proposal to Mark but it is too soon now to do \n",
      "so and I'm not sure that I could fit it in.  Alos, Mark mentioned that I \n",
      "should be getting something in the mail about some stock options that I \n",
      "apparently received recently.  Could you please be on the look-out for it?  \n",
      "I'm not sure whther all of the lawyers got some so please keep this quiet \n",
      "(which I know you will).\n",
      "\n",
      "As for Bill's mother, she turns 80 this week and everyone in the family \n",
      "except Bill and I is going to Florida next weekend for a visit.  I told Bill \n",
      "that he could go but he decided not to.  We bought her some really pretty \n",
      "(and expensive) earrings which I hope she will like.  She has not yet given \n",
      "us a date for her visit and I can't figure out if we are still in the \n",
      "doghouse with her or not because we didn't let her come this past week.  I \n",
      "really don't care what she thinks because it was the right thing to do.\n",
      "\n",
      "Well, I've got to go.  hope you had a good weekend and feel free to stop by \n",
      "for a visit.\n",
      "\n",
      "Carol\n",
      "\n",
      "\n",
      "\n",
      "\tSuzanne Adams\n",
      "\t07/27/00 05:34 PM\n",
      "\t\t\n",
      "\t\t To: Carol St Clair/HOU/ECT@ECT\n",
      "\t\t cc: \n",
      "\t\t Subject: Re: Invoice\n",
      "\n",
      "How are things going at home?  You doing ok? Charles?\n",
      "\n",
      "\n",
      "\n",
      "\tCarol St Clair\n",
      "\t07/27/2000 05:20 PM\n",
      "\t\t\n",
      "\t\t To: Suzanne Adams/HOU/ECT@ECT\n",
      "\t\t cc: \n",
      "\t\t Subject: Re: Invoice\n",
      "\n",
      "Please give this invoice to Mark and please call whoever sent it and tell \n",
      "them to address all future invoices to Mark.  Thanks.\n",
      "\n",
      "Carol St. Clair\n",
      "EB 3892\n",
      "713-853-3989 (Phone)\n",
      "713-646-3393 (Fax)\n",
      "carol.st.clair@enron.com\n",
      "\n",
      "\n",
      "\n",
      "\tSuzanne Adams\n",
      "\t07/26/00 03:45 PM\n",
      "\t\t \n",
      "\t\t To: Carol St Clair/HOU/ECT@ECT\n",
      "\t\t cc: \n",
      "\t\t Subject: Invoice\n",
      "\n",
      "Carol, I received an invoice from LeBoeuf Lamb regarding the ACE insurance \n",
      "matter.  What should be done with it?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# enter matching index from list above\n",
    "enter_id = 450200\n",
    "print(query.loc[enter_id,'content_str'])\n",
    "\n",
    "# store ids here in the form {123: 1, 456: 1, ...}\n",
    "target_ids = {450200: 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Random Sample for Labeling\n",
    "\n",
    "Reviewed 200 examples in first 50,000 emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample set shape: (200, 5)\n"
     ]
    }
   ],
   "source": [
    "# keep seed = 24 for sample of first 50000 emails\n",
    "random.seed(24)\n",
    "rand_num = 100\n",
    "rand_ids_1 = random.sample(range(2000), rand_num)\n",
    "rand_ids_2 = random.sample(range(2000,50000), rand_num)\n",
    "rand_ids = rand_ids_1 + rand_ids_2\n",
    "rand_set = emails_df.loc[rand_ids,]\n",
    "#print(rand_ids)\n",
    "print(\"Sample set shape:\", rand_set.shape)\n",
    "#for id_ in rand_ids:\n",
    "#    print(id_)\n",
    "#    print(rand_set.loc[id_, 'content_str'])\n",
    "\n",
    "# assign labels based on id\n",
    "label_dict = {373: 1, 346: 1, 405: 1, 27091: 1, 13966: 1}\n",
    "rand_set[\"suspicious_ind\"] = np.zeros(len(rand_ids))\n",
    "for k in label_dict.keys():\n",
    "    rand_set.loc[k, \"suspicious_ind\"] = label_dict.get(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "      <th>content_tokens</th>\n",
       "      <th>content_IDS</th>\n",
       "      <th>suspicious_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>allen-p/deleted_items/381.</td>\n",
       "      <td>Message-ID: &lt;26393700.1075862162007.JavaMail.e...</td>\n",
       "      <td>[IMAGE]\\n [IMAGE][IMAGE]       [IMAGE] Yahoo! ...</td>\n",
       "      <td>[[, image, ], [, image, ], [, image, ], [, ima...</td>\n",
       "      <td>[0, 78, 107, 79, 78, 107, 79, 78, 107, 79, 78,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>allen-p/all_documents/266.</td>\n",
       "      <td>Message-ID: &lt;16945.1075855671306.JavaMail.evan...</td>\n",
       "      <td>Kay &amp; Neal,\\n\\nThanks for remembering my birth...</td>\n",
       "      <td>[kay, &amp;, neal, ,, thanks, for, remembering, my...</td>\n",
       "      <td>[0, 2, 43, 2, 3, 102, 16, 2, 94, 2, 4, 1, 0, 1...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>allen-p/discussion_threads/212.</td>\n",
       "      <td>Message-ID: &lt;19120705.1075855677934.JavaMail.e...</td>\n",
       "      <td>Attached  are two files that illustrate the fo...</td>\n",
       "      <td>[attached, are, two, files, that, illustrate, ...</td>\n",
       "      <td>[0, 198, 41, 181, 2, 25, 2, 5, 197, 9, 44, 359...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>allen-p/all_documents/73.</td>\n",
       "      <td>Message-ID: &lt;22565759.1075855667097.JavaMail.e...</td>\n",
       "      <td>Put me down as a reviewer</td>\n",
       "      <td>[put, me, down, as, a, reviewer]</td>\n",
       "      <td>[0, 412, 72, 302, 44, 14, 2, 1]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>allen-p/_sent_mail/439.</td>\n",
       "      <td>Message-ID: &lt;14134673.1075855725697.JavaMail.e...</td>\n",
       "      <td>Jacques,\\n\\nStill trying to close the loop on ...</td>\n",
       "      <td>[jacques, ,, still, trying, to, close, the, lo...</td>\n",
       "      <td>[0, 2, 3, 226, 846, 7, 583, 5, 2, 20, 5, 54, 1...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file  \\\n",
       "1458       allen-p/deleted_items/381.   \n",
       "784        allen-p/all_documents/266.   \n",
       "1719  allen-p/discussion_threads/212.   \n",
       "1193        allen-p/all_documents/73.   \n",
       "373           allen-p/_sent_mail/439.   \n",
       "\n",
       "                                                message  \\\n",
       "1458  Message-ID: <26393700.1075862162007.JavaMail.e...   \n",
       "784   Message-ID: <16945.1075855671306.JavaMail.evan...   \n",
       "1719  Message-ID: <19120705.1075855677934.JavaMail.e...   \n",
       "1193  Message-ID: <22565759.1075855667097.JavaMail.e...   \n",
       "373   Message-ID: <14134673.1075855725697.JavaMail.e...   \n",
       "\n",
       "                                            content_str  \\\n",
       "1458  [IMAGE]\\n [IMAGE][IMAGE]       [IMAGE] Yahoo! ...   \n",
       "784   Kay & Neal,\\n\\nThanks for remembering my birth...   \n",
       "1719  Attached  are two files that illustrate the fo...   \n",
       "1193                          Put me down as a reviewer   \n",
       "373   Jacques,\\n\\nStill trying to close the loop on ...   \n",
       "\n",
       "                                         content_tokens  \\\n",
       "1458  [[, image, ], [, image, ], [, image, ], [, ima...   \n",
       "784   [kay, &, neal, ,, thanks, for, remembering, my...   \n",
       "1719  [attached, are, two, files, that, illustrate, ...   \n",
       "1193                   [put, me, down, as, a, reviewer]   \n",
       "373   [jacques, ,, still, trying, to, close, the, lo...   \n",
       "\n",
       "                                            content_IDS  suspicious_ind  \n",
       "1458  [0, 78, 107, 79, 78, 107, 79, 78, 107, 79, 78,...             0.0  \n",
       "784   [0, 2, 43, 2, 3, 102, 16, 2, 94, 2, 4, 1, 0, 1...             0.0  \n",
       "1719  [0, 198, 41, 181, 2, 25, 2, 5, 197, 9, 44, 359...             0.0  \n",
       "1193                    [0, 412, 72, 302, 44, 14, 2, 1]             0.0  \n",
       "373   [0, 2, 3, 226, 846, 7, 583, 5, 2, 20, 5, 54, 1...             1.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Raw Email Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Tokens: 15743385\n"
     ]
    }
   ],
   "source": [
    "# tokenize and canonicalize each email to get vocab\n",
    "# WARNING: THIS STEP TAKES ~40 MINUTES ON LOCAL MACHINE WHEN USING ALL 500K EMAILS\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "all_tokens = []\n",
    "email_tokens = []\n",
    "\n",
    "for i, body in enumerate(emails_df[\"content_str\"]):\n",
    "    #get sentence level\n",
    "    sents = nltk.tokenize.sent_tokenize(body)\n",
    "    canon = []\n",
    "    for sent in sents:\n",
    "        #list of tokens in sentence\n",
    "        sent_tokens = tokenizer.tokenize(sent)\n",
    "        canon += utils.canonicalize_words(sent_tokens)\n",
    "    all_tokens += canon\n",
    "    email_tokens.append(canon)\n",
    "\n",
    "emails_df[\"content_tokens\"] = email_tokens\n",
    "print(\"Total Number of Tokens:\", len(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 30,000\n",
      "Unigrams:  167039\n"
     ]
    }
   ],
   "source": [
    "# build vocab\n",
    "# V = size\n",
    "V = 30000\n",
    "vocab = vocabulary.Vocabulary(all_tokens, size=V)\n",
    "print(\"Vocabulary size: {:,}\".format(vocab.size))\n",
    "vocab_ids = vocab.words_to_ids(all_tokens)\n",
    "print(\"Unigrams: \", len(vocab.unigram_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 954, 1896, 4, 1, 0, 219, 7, 193, 59, 59, 1, 0, 59, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess email bodies with unknowns and sentence buffers\n",
    "emails_preprocessed = []\n",
    "\n",
    "for i, body in enumerate(emails_df[\"content_str\"]):\n",
    "    #get sentence level\n",
    "    sents = nltk.tokenize.sent_tokenize(body)\n",
    "    list_sents = []\n",
    "    for sent in sents:\n",
    "        #list of tokens in sentence\n",
    "        sent_tokens = tokenizer.tokenize(sent)\n",
    "        list_sents.append(sent_tokens)\n",
    "    #preprocessed = list(utils.preprocess_sentences(list_sents, vocab, use_eos=True, emit_ids=False))\n",
    "    #just keep word IDs\n",
    "    preprocessed = list(utils.preprocess_sentences(list_sents, vocab, use_eos=True, emit_ids=True))\n",
    "    emails_preprocessed.append(preprocessed)\n",
    "\n",
    "emails_df[\"content_IDS\"] = emails_preprocessed\n",
    "emails_preprocessed[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'test',\n",
       " 'successful',\n",
       " '.',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'way',\n",
       " 'to',\n",
       " 'go',\n",
       " '!',\n",
       " '!',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '!',\n",
       " '</s>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test ID to word\n",
    "vocab.ids_to_words(emails_df.loc[2, \"content_IDS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "      <th>content_tokens</th>\n",
       "      <th>content_IDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>[here, is, our, forecast]</td>\n",
       "      <td>[0, 139, 21, 74, 2693, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>[traveling, to, have, a, business, meeting, ta...</td>\n",
       "      <td>[0, 3838, 7, 37, 14, 133, 123, 1805, 5, 1140, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>[test, successful, ., way, to, go, !, !, !]</td>\n",
       "      <td>[0, 954, 1896, 4, 1, 0, 219, 7, 193, 59, 59, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>[randy, ,, can, you, send, me, a, schedule, of...</td>\n",
       "      <td>[0, 1086, 3, 69, 17, 274, 72, 14, 389, 12, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>[let, 's, shoot, for, tuesday, at, DGDG:DGDG, .]</td>\n",
       "      <td>[0, 129, 40, 6339, 16, 245, 34, 55, 4, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  \\\n",
       "0     allen-p/_sent_mail/1.   \n",
       "1    allen-p/_sent_mail/10.   \n",
       "2   allen-p/_sent_mail/100.   \n",
       "3  allen-p/_sent_mail/1000.   \n",
       "4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
       "\n",
       "                                         content_str  \\\n",
       "0                          Here is our forecast\\n\\n    \n",
       "1  Traveling to have a business meeting takes the...   \n",
       "2                     test successful.  way to go!!!   \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...   \n",
       "4                Let's shoot for Tuesday at 11:45.     \n",
       "\n",
       "                                      content_tokens  \\\n",
       "0                          [here, is, our, forecast]   \n",
       "1  [traveling, to, have, a, business, meeting, ta...   \n",
       "2        [test, successful, ., way, to, go, !, !, !]   \n",
       "3  [randy, ,, can, you, send, me, a, schedule, of...   \n",
       "4   [let, 's, shoot, for, tuesday, at, DGDG:DGDG, .]   \n",
       "\n",
       "                                         content_IDS  \n",
       "0                          [0, 139, 21, 74, 2693, 1]  \n",
       "1  [0, 3838, 7, 37, 14, 133, 123, 1805, 5, 1140, ...  \n",
       "2  [0, 954, 1896, 4, 1, 0, 219, 7, 193, 59, 59, 1...  \n",
       "3  [0, 1086, 3, 69, 17, 274, 72, 14, 389, 12, 5, ...  \n",
       "4          [0, 129, 40, 6339, 16, 245, 34, 55, 4, 1]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate BOW features and longer N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW shape: (50000, 30000)\n",
      "TF-IDF:    (50000, 30000)\n"
     ]
    }
   ],
   "source": [
    "# generate BOW features based on vocab.size V (above) and transform to TF-IDF\n",
    "# uses canonicalized words\n",
    "bow_feats = utils.id_lists_to_sparse_bow(emails_df[\"content_IDS\"], vocab.size)\n",
    "print(\"BOW shape: \", bow_feats.shape)\n",
    "transformer = TfidfTransformer()\n",
    "bow_tfidf = transformer.fit_transform(bow_feats)\n",
    "print(\"BOW TF-IDF:\", bow_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-grams shape:  (50000, 1560)\n",
      "N-grams TF-IDF: (50000, 1560)\n"
     ]
    }
   ],
   "source": [
    "# consider longer n-grams\n",
    "vectorize = CountVectorizer(ngram_range=(2, 3), max_df=.3, min_df=.01)\n",
    "n_grams = vectorize.fit_transform(emails_df[\"content_str\"])\n",
    "print(\"N-grams shape: \", n_grams.shape)\n",
    "\n",
    "n_grams_idf = transformer.fit_transform(n_grams)\n",
    "print(\"N-grams TF-IDF:\", n_grams_idf.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
