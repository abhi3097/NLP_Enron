{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os, sys\n",
    "import collections\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse, hstack\n",
    "import email\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "\n",
    "# Helper libraries\n",
    "import constants\n",
    "import utils\n",
    "import vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Email Bodies\n",
    "Data source and exploration code: [Kaggle](https://www.kaggle.com/zichen/explore-enron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (517401, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv dataset - download from Kaggle (linked above, ~.5gb)\n",
    "\n",
    "# replace with local path\n",
    "path = 'C:/Users/Colby/Documents/Berkeley/266_NLP/final_project/data'\n",
    "\n",
    "# all emails for targeted search\n",
    "all_emails = pd.read_csv(path + '/emails.csv')\n",
    "#emails_df = pd.read_csv(path + '/emails.csv', rows = 50000)\n",
    "\n",
    "print(\"Shape:\", all_emails.shape)\n",
    "all_emails.head()\n",
    "#print(all_emails['message'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full shape: (517401, 3)\n",
      "Mini shape: (50000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  \\\n",
       "0     allen-p/_sent_mail/1.   \n",
       "1    allen-p/_sent_mail/10.   \n",
       "2   allen-p/_sent_mail/100.   \n",
       "3  allen-p/_sent_mail/1000.   \n",
       "4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
       "\n",
       "                                         content_str  \n",
       "0                          Here is our forecast\\n\\n   \n",
       "1  Traveling to have a business meeting takes the...  \n",
       "2                     test successful.  way to go!!!  \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...  \n",
       "4                Let's shoot for Tuesday at 11:45.    "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# citation: Kaggle exploration code\n",
    "# isolate email body\n",
    "# run-time: ~ 3 minutes on full dataset\n",
    "\n",
    "def get_text_from_email(msg):\n",
    "    '''To get the content from email objects'''\n",
    "    parts = []\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            parts.append( part.get_payload() )\n",
    "    return ''.join(parts)\n",
    "\n",
    "# Parse the emails into a list email objects\n",
    "messages = list(map(email.message_from_string, all_emails['message']))\n",
    "#emails_df.drop('message', axis=1, inplace=True)\n",
    "\n",
    "# Parse content from emails\n",
    "all_emails['content_str'] = list(map(get_text_from_email, messages))\n",
    "\n",
    "del messages\n",
    "\n",
    "\n",
    "# mini version for preprocessing (to save run-time)\n",
    "size = 50000\n",
    "emails_df = all_emails.loc[range(size),]\n",
    "print(\"Full shape:\", all_emails.shape)\n",
    "print(\"Mini shape:\", emails_df.shape)\n",
    "\n",
    "all_emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Raw Contents for Suspicious Phrases\n",
    "### Store dataframe indexes\n",
    "Use this block to search raw messages and store the row indexes in *target_ids*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 3)\n",
      "Matching indexes: [10682, 13050, 13303, 13670, 14541, 14730, 16044, 16212, 16939, 18363, 21033, 21037, 21517, 22948, 22955, 23896, 27214, 31595, 31599, 32079, 36857, 36889, 37145, 37341, 39709, 46081, 51752, 58238, 59058, 60853, 60854, 60859, 63049, 63065, 63081, 63168, 63254, 63373, 66148, 67658, 69838, 72252, 72256, 72257, 72740, 72759, 72813, 72939, 73895, 74539, 76896, 79697, 83561, 85227, 86243, 88247, 94130, 96350, 97913, 101716, 107626, 110149, 119809, 144020, 145633, 146735, 146776, 148558, 148966, 150518, 165518, 166075, 180538, 195232, 212248, 213120, 221997, 265332, 270277, 271537, 275666, 276081, 276083, 276085, 276086, 277318, 277319, 277321, 277324, 279530, 292182, 292297, 296283, 298164, 298166, 298167, 298168, 298169, 298170, 298171, 298172, 298173, 298174, 298175, 298177, 298178, 298179, 298180, 298181, 298186, 303544, 303545, 307533, 307535, 310739, 310740, 310741, 310742, 320741, 320742, 323096, 329104, 348760, 352897, 355211, 357850, 358102, 368444, 372226, 372964, 374271, 390509, 390519, 404668, 404939, 405896, 407748, 407924, 407980, 410631, 411486, 431111, 433305, 442921, 444117, 445266, 446017, 461778, 462315, 464346, 465556, 471474, 472261, 477117, 485161, 504267, 510339, 512854, 513165, 513894]\n"
     ]
    }
   ],
   "source": [
    "# test phrase - enter between quotes\n",
    "phrase = \"and stuff\"\n",
    "\n",
    "query = all_emails[all_emails['content_str'].str.contains(phrase, case=False)]\n",
    "print(query.shape)\n",
    "print(\"Matching indexes:\", query.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is cute,  things like this help during difficult times\n",
      "\n",
      "-----Original Message-----\n",
      "From: Rick Cates [mailto:rd_cates@yahoo.com]\n",
      "Sent: Monday, December 03, 2001 11:03 AM\n",
      "To: Brickman, Ronnie; Guy Bruner; Campbell, Larry; Chris Gerald; raymond\n",
      "hanover; Haug, Steve; Ben Howard; Bill Jones; Loveless, Rick; Nichols,\n",
      "Leo; John Rose\n",
      "Subject: Fwd: Retirement in a Trailer Park\n",
      "\n",
      "\n",
      "> RETIREMENT IN A TRAILER  PARK THRU THE EYES OF A\n",
      "> CHILD This is just too\n",
      "> cute! \n",
      "> \n",
      "> After a spring  break, a teacher asked her young\n",
      "> pupils how they  spent\n",
      "> the holidays. One  child wrote the following: \n",
      "> \n",
      "> \"We always used to spend the holidays with Grandma\n",
      "> and Grandpa. They used\n",
      ">  to live here in a big brick house, but Grandpa got\n",
      "> retarded and they\n",
      "> moved  to Arizona.    \n",
      "> \n",
      "> Now they live in a  place with a lot of other\n",
      "> retarded  people.  They\n",
      "> live in a tin box  and have rocks painted green to\n",
      "> look like grass.  They\n",
      "> ride around on big tricycles and wear name tags\n",
      "> because they don't  know\n",
      "> who they are anymore.  They go to a building called\n",
      "> a wrecked center, but\n",
      "> they must have got it  fixed, because it is all\n",
      "> right now. They play\n",
      "> games and do exercises  there, but they don't do\n",
      "> them very well. There is\n",
      "> a swimming pool too,  but  they all jump up and down\n",
      "> in it with their\n",
      "> hats on. I guess they don't know how to swim.   \n",
      "> \n",
      "> At their gate, there is a doll house with a little\n",
      "> old man sitting in it.\n",
      ">  He watches all day so nobody can escape. Sometimes\n",
      "> they sneak out.  Then\n",
      ">  they go cruising in their golf carts. \n",
      "> \n",
      "> My Grandma used to bake cookies and stuff, but I\n",
      "> guess she forgot how. \n",
      "> Nobody there cooks, they just eat out. And they eat\n",
      "> the same thing every \n",
      "> night, \"Early Birds. \"  Some of the people can't get\n",
      "> past the man in the \n",
      "> doll house to go out. So the ones who do get out\n",
      "> bring food back to the \n",
      "> wrecked center and call it pot luck. \n",
      "> \n",
      "> My Grandma says Grandpa's worked all his life to\n",
      "> earn his retardment and \n",
      "> says I should work hard so I  can be retarded\n",
      "> someday too. When I earn my\n",
      ">  retardment I want to be  the man in the doll house.\n",
      "> Then I will let\n",
      "> people  out so they can visit their grandchildren. \"\n",
      "> \n",
      "> \n",
      "\n",
      "\n",
      "__________________________________________________\n",
      "Do You Yahoo!?\n",
      "Buy the perfect holiday gifts at Yahoo! Shopping.\n",
      "http://shopping.yahoo.com\n"
     ]
    }
   ],
   "source": [
    "# enter matching index from list above\n",
    "enter_id = 46081\n",
    "print(query.loc[enter_id,'content_str'])\n",
    "\n",
    "# store ids here in the form {123: 1, 456: 1, ...}\n",
    "target_ids = {16212: 1, 450200: 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Random Sample for Labeling\n",
    "\n",
    "Reviewed 200 examples in first 50,000 emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample set shape: (200, 3)\n"
     ]
    }
   ],
   "source": [
    "# keep seed = 24 for sample of first 50000 emails\n",
    "random.seed(24)\n",
    "rand_num = 100\n",
    "rand_ids_1 = random.sample(range(2000), rand_num)\n",
    "rand_ids_2 = random.sample(range(2000,50000), rand_num)\n",
    "rand_ids = rand_ids_1 + rand_ids_2\n",
    "rand_set = emails_df.loc[rand_ids,]\n",
    "#print(rand_ids)\n",
    "print(\"Sample set shape:\", rand_set.shape)\n",
    "#for id_ in rand_ids:\n",
    "#    print(id_)\n",
    "#    print(rand_set.loc[id_, 'content_str'])\n",
    "\n",
    "# assign labels based on id\n",
    "label_dict = {373: 1, 346: 1, 405: 1, 27091: 1, 13966: 1}\n",
    "rand_set[\"suspicious_ind\"] = np.zeros(len(rand_ids))\n",
    "for k in label_dict.keys():\n",
    "    rand_set.loc[k, \"suspicious_ind\"] = label_dict.get(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "      <th>suspicious_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>allen-p/deleted_items/381.</td>\n",
       "      <td>Message-ID: &lt;26393700.1075862162007.JavaMail.e...</td>\n",
       "      <td>[IMAGE]\\n [IMAGE][IMAGE]       [IMAGE] Yahoo! ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>allen-p/all_documents/266.</td>\n",
       "      <td>Message-ID: &lt;16945.1075855671306.JavaMail.evan...</td>\n",
       "      <td>Kay &amp; Neal,\\n\\nThanks for remembering my birth...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>allen-p/discussion_threads/212.</td>\n",
       "      <td>Message-ID: &lt;19120705.1075855677934.JavaMail.e...</td>\n",
       "      <td>Attached  are two files that illustrate the fo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>allen-p/all_documents/73.</td>\n",
       "      <td>Message-ID: &lt;22565759.1075855667097.JavaMail.e...</td>\n",
       "      <td>Put me down as a reviewer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>allen-p/_sent_mail/439.</td>\n",
       "      <td>Message-ID: &lt;14134673.1075855725697.JavaMail.e...</td>\n",
       "      <td>Jacques,\\n\\nStill trying to close the loop on ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file  \\\n",
       "1458       allen-p/deleted_items/381.   \n",
       "784        allen-p/all_documents/266.   \n",
       "1719  allen-p/discussion_threads/212.   \n",
       "1193        allen-p/all_documents/73.   \n",
       "373           allen-p/_sent_mail/439.   \n",
       "\n",
       "                                                message  \\\n",
       "1458  Message-ID: <26393700.1075862162007.JavaMail.e...   \n",
       "784   Message-ID: <16945.1075855671306.JavaMail.evan...   \n",
       "1719  Message-ID: <19120705.1075855677934.JavaMail.e...   \n",
       "1193  Message-ID: <22565759.1075855667097.JavaMail.e...   \n",
       "373   Message-ID: <14134673.1075855725697.JavaMail.e...   \n",
       "\n",
       "                                            content_str  suspicious_ind  \n",
       "1458  [IMAGE]\\n [IMAGE][IMAGE]       [IMAGE] Yahoo! ...             0.0  \n",
       "784   Kay & Neal,\\n\\nThanks for remembering my birth...             0.0  \n",
       "1719  Attached  are two files that illustrate the fo...             0.0  \n",
       "1193                          Put me down as a reviewer             0.0  \n",
       "373   Jacques,\\n\\nStill trying to close the loop on ...             1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Raw Email Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Tokens: 15743385\n"
     ]
    }
   ],
   "source": [
    "# tokenize and canonicalize each email to get vocab\n",
    "# WARNING: THIS STEP TAKES ~40 MINUTES ON LOCAL MACHINE WHEN USING ALL 500K EMAILS\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "all_tokens = []\n",
    "email_tokens = []\n",
    "\n",
    "for i, body in enumerate(emails_df[\"content_str\"]):\n",
    "    #get sentence level\n",
    "    sents = nltk.tokenize.sent_tokenize(body)\n",
    "    canon = []\n",
    "    for sent in sents:\n",
    "        #list of tokens in sentence\n",
    "        sent_tokens = tokenizer.tokenize(sent)\n",
    "        canon += utils.canonicalize_words(sent_tokens)\n",
    "    all_tokens += canon\n",
    "    email_tokens.append(canon)\n",
    "\n",
    "emails_df[\"content_tokens\"] = email_tokens\n",
    "print(\"Total Number of Tokens:\", len(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 5,000\n",
      "Unigrams:  167039\n"
     ]
    }
   ],
   "source": [
    "# build vocab\n",
    "# V = size\n",
    "V = 5000\n",
    "vocab = vocabulary.Vocabulary(all_tokens, size=V)\n",
    "print(\"Vocabulary size: {:,}\".format(vocab.size))\n",
    "vocab_ids = vocab.words_to_ids(all_tokens)\n",
    "print(\"Unigrams: \", len(vocab.unigram_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 954, 1895, 4, 1, 0, 219, 7, 193, 59, 59, 1, 0, 59, 1]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess email bodies with unknowns and sentence buffers\n",
    "emails_preprocessed = []\n",
    "\n",
    "for i, body in enumerate(emails_df[\"content_str\"]):\n",
    "    #get sentence level\n",
    "    sents = nltk.tokenize.sent_tokenize(body)\n",
    "    list_sents = []\n",
    "    for sent in sents:\n",
    "        #list of tokens in sentence\n",
    "        sent_tokens = tokenizer.tokenize(sent)\n",
    "        list_sents.append(sent_tokens)\n",
    "    #preprocessed = list(utils.preprocess_sentences(list_sents, vocab, use_eos=True, emit_ids=False))\n",
    "    #just keep word IDs\n",
    "    preprocessed = list(utils.preprocess_sentences(list_sents, vocab, use_eos=True, emit_ids=True))\n",
    "    emails_preprocessed.append(preprocessed)\n",
    "\n",
    "emails_df[\"content_IDS\"] = emails_preprocessed\n",
    "emails_preprocessed[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'test',\n",
       " 'successful',\n",
       " '.',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'way',\n",
       " 'to',\n",
       " 'go',\n",
       " '!',\n",
       " '!',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '!',\n",
       " '</s>']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test ID to word\n",
    "vocab.ids_to_words(emails_df.loc[2, \"content_IDS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final preprocessed strings for feature generation\n",
    "emails_df[\"content_proc\"] = emails_df[\"content_IDS\"].apply(lambda x: ' '.join(vocab.ids_to_words(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate BOW features and longer N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "      <th>content_tokens</th>\n",
       "      <th>content_IDS</th>\n",
       "      <th>email_length</th>\n",
       "      <th>content_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>[here, is, our, forecast]</td>\n",
       "      <td>[0, 139, 21, 74, 2697, 1]</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;s&gt; here is our forecast &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>[traveling, to, have, a, business, meeting, ta...</td>\n",
       "      <td>[0, 3835, 7, 37, 14, 133, 123, 1804, 5, 1140, ...</td>\n",
       "      <td>171</td>\n",
       "      <td>&lt;s&gt; traveling to have a business meeting takes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>[test, successful, ., way, to, go, !, !, !]</td>\n",
       "      <td>[0, 954, 1895, 4, 1, 0, 219, 7, 193, 59, 59, 1...</td>\n",
       "      <td>15</td>\n",
       "      <td>&lt;s&gt; test successful . &lt;/s&gt; &lt;s&gt; way to go ! ! &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>[randy, ,, can, you, send, me, a, schedule, of...</td>\n",
       "      <td>[0, 1086, 3, 69, 17, 274, 72, 14, 389, 12, 5, ...</td>\n",
       "      <td>45</td>\n",
       "      <td>&lt;s&gt; randy , can you send me a schedule of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>[let, 's, shoot, for, tuesday, at, DGDG:DGDG, .]</td>\n",
       "      <td>[0, 129, 40, 2, 16, 245, 34, 55, 4, 1]</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;s&gt; let 's &lt;unk&gt; for tuesday at DGDG:DGDG . &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  \\\n",
       "0     allen-p/_sent_mail/1.   \n",
       "1    allen-p/_sent_mail/10.   \n",
       "2   allen-p/_sent_mail/100.   \n",
       "3  allen-p/_sent_mail/1000.   \n",
       "4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
       "\n",
       "                                         content_str  \\\n",
       "0                          Here is our forecast\\n\\n    \n",
       "1  Traveling to have a business meeting takes the...   \n",
       "2                     test successful.  way to go!!!   \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...   \n",
       "4                Let's shoot for Tuesday at 11:45.     \n",
       "\n",
       "                                      content_tokens  \\\n",
       "0                          [here, is, our, forecast]   \n",
       "1  [traveling, to, have, a, business, meeting, ta...   \n",
       "2        [test, successful, ., way, to, go, !, !, !]   \n",
       "3  [randy, ,, can, you, send, me, a, schedule, of...   \n",
       "4   [let, 's, shoot, for, tuesday, at, DGDG:DGDG, .]   \n",
       "\n",
       "                                         content_IDS  email_length  \\\n",
       "0                          [0, 139, 21, 74, 2697, 1]             6   \n",
       "1  [0, 3835, 7, 37, 14, 133, 123, 1804, 5, 1140, ...           171   \n",
       "2  [0, 954, 1895, 4, 1, 0, 219, 7, 193, 59, 59, 1...            15   \n",
       "3  [0, 1086, 3, 69, 17, 274, 72, 14, 389, 12, 5, ...            45   \n",
       "4             [0, 129, 40, 2, 16, 245, 34, 55, 4, 1]            10   \n",
       "\n",
       "                                        content_proc  \n",
       "0                      <s> here is our forecast </s>  \n",
       "1  <s> traveling to have a business meeting takes...  \n",
       "2  <s> test successful . </s> <s> way to go ! ! <...  \n",
       "3  <s> randy , can you send me a schedule of the ...  \n",
       "4   <s> let 's <unk> for tuesday at DGDG:DGDG . </s>  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# email length feature\n",
    "emails_df[\"email_length\"] = emails_df[\"content_IDS\"].apply(len)\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW shape:  (50000, 5000)\n",
      "BOW TF-IDF: (50000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# generate BOW features based on vocab.size V (above) and transform to TF-IDF\n",
    "# uses canonicalized words\n",
    "bow_feats = utils.id_lists_to_sparse_bow(emails_df[\"content_IDS\"], vocab.size)\n",
    "print(\"BOW shape: \", bow_feats.shape)\n",
    "transformer = TfidfTransformer()\n",
    "bow_tfidf = transformer.fit_transform(bow_feats)\n",
    "print(\"BOW TF-IDF:\", bow_tfidf.shape)\n",
    "\n",
    "# TOO MANY ODD TOKENS CAPTURED BY VOCAB OBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-grams shape:  (50000, 3939)\n",
      "N-grams TF-IDF: (50000, 3939)\n"
     ]
    }
   ],
   "source": [
    "# consider longer n-grams\n",
    "vectorize = CountVectorizer(ngram_range=(1, 3), max_df=.2, min_df=.01)\n",
    "n_grams = vectorize.fit_transform(emails_df[\"content_proc\"])\n",
    "print(\"N-grams shape: \", n_grams.shape)\n",
    "\n",
    "n_grams_idf = transformer.fit_transform(n_grams)\n",
    "print(\"N-grams TF-IDF:\", n_grams_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3939)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join features\n",
    "length_sparse = sparse.csr_matrix(emails_df[\"email_length\"]).transpose()\n",
    "# with length feature\n",
    "#feature_vects = sparse.hstack([length_sparse, bow_tfidf, n_grams_idf])\n",
    "#feature_vects = sparse.hstack([bow_tfidf, n_grams_idf])\n",
    "feature_vects = n_grams_idf\n",
    "feature_vects.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit & Evaluate Simple K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=4, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.01, verbose=0)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit k-means (n=4, tol=.01, max_iter=100 takes ~20 mins to train)\n",
    "kmeans = KMeans(n_clusters=4, tol=.01, max_iter=100)\n",
    "kmeans.fit(feature_vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 clusters: [0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 2 0 0]\n",
      "Positive labels:   [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions on positively labeled examples\n",
    "base_preds = kmeans.predict(feature_vects)\n",
    "print(\"First 30 clusters:\", base_preds[:30])\n",
    "print(\"Positive labels:  \", base_preds[list(label_dict.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3939)\n"
     ]
    }
   ],
   "source": [
    "# evaluate closest examples in cluster 2 based on cosine similarity\n",
    "suspicious_ids = np.zeros(len(base_preds))\n",
    "for k in label_dict.keys():\n",
    "    suspicious_ids[k] = label_dict.get(k)\n",
    "\n",
    "# enter index of typical cluster\n",
    "key_cluster = 0\n",
    "\n",
    "cluster_ids = (base_preds==key_cluster).astype(int)\n",
    "\n",
    "features_np = sparse.csr_matrix.todense(feature_vects)\n",
    "\n",
    "labeled_feats = features_np[np.multiply(suspicious_ids, cluster_ids).astype(bool)]\n",
    "print(labeled_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([346, 27091, 373, 13966, 405])\n",
      "(5, 50000)\n",
      "[[    0 10648 34952 10650 10651 34951 10653 34950 10655 34949]\n",
      " [    0  4375 46359 14860 40413  4371 40412  4369  4368 46362]\n",
      " [    0 15079 15080  4657 37824 37820 37816 37815 15107 37808]\n",
      " [    0 38573 19107 19105 38576 38577 38578 19100 19099 19098]\n",
      " [    0 46059 10570 10571 36744 46055 10575 29488 10583 10584]]\n"
     ]
    }
   ],
   "source": [
    "# cosine_similarity\n",
    "print(label_dict.keys())\n",
    "cos_sims = cosine_similarity(labeled_feats, feature_vects)\n",
    "print(cos_sims.shape)\n",
    "closest = np.argsort(cos_sims, axis = 1)\n",
    "print(closest[:,0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> lets discuss this before we make offer . </s> <s> rick </s>'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nearest emails flagged:\n",
    "emails_df.loc[37820 , \"content_proc\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
