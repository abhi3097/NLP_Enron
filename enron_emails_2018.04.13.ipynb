{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os, sys\n",
    "import collections\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import email\n",
    "import nltk\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from scipy import sparse, hstack\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import constants\n",
    "import utils\n",
    "import vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Email Bodies\n",
    "Data source and exploration code: [Kaggle](https://www.kaggle.com/zichen/explore-enron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (517401, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv dataset - download from Kaggle (linked above, ~.5gb)\n",
    "\n",
    "# replace with local path\n",
    "path = '/mnt/c/Users/clay/Desktop/w266'\n",
    "\n",
    "# all emails for targeted search\n",
    "all_emails = pd.read_csv(path + '/emails.csv')\n",
    "#emails_df = pd.read_csv(path + '/emails.csv', rows = 50000)\n",
    "\n",
    "print(\"Shape:\", all_emails.shape)\n",
    "all_emails.head()\n",
    "#print(all_emails['message'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# citation: Kaggle exploration code\n",
    "# isolate email body\n",
    "# run-time: ~ 3 minutes on full dataset\n",
    "\n",
    "def get_text_from_email(msg):\n",
    "    '''To get the content from email objects'''\n",
    "    parts = []\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            parts.append( part.get_payload() )\n",
    "    return ''.join(parts)\n",
    "\n",
    "# Parse the emails into a list email objects\n",
    "messages = list(map(email.message_from_string, all_emails['message']))\n",
    "#emails_df.drop('message', axis=1, inplace=True)\n",
    "\n",
    "# Parse content from emails\n",
    "all_emails['content_str'] = list(map(get_text_from_email, messages))\n",
    "\n",
    "del messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full shape: (517401, 3)\n",
      "Mini shape: (5000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  \\\n",
       "0     allen-p/_sent_mail/1.   \n",
       "1    allen-p/_sent_mail/10.   \n",
       "2   allen-p/_sent_mail/100.   \n",
       "3  allen-p/_sent_mail/1000.   \n",
       "4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
       "\n",
       "                                         content_str  \n",
       "0                          Here is our forecast\\n\\n   \n",
       "1  Traveling to have a business meeting takes the...  \n",
       "2                     test successful.  way to go!!!  \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...  \n",
       "4                Let's shoot for Tuesday at 11:45.    "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mini version for preprocessing (to save run-time)\n",
    "size = 5000\n",
    "emails_df = all_emails.loc[range(size),]\n",
    "print(\"Full shape:\", all_emails.shape)\n",
    "print(\"Mini shape:\", emails_df.shape)\n",
    "\n",
    "# for full preprocessing and training\n",
    "emails_df = all_emails\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Raw Email Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACED\n",
    "\n",
    "# tokenize and canonicalize each email to get vocab\n",
    "# WARNING: THIS STEP TAKES ~30 MINUTES ON LOCAL MACHINE WHEN USING ALL 500K EMAILS\n",
    "#tokenizer = TreebankWordTokenizer()\n",
    "#all_tokens = []\n",
    "#email_tokens = []\n",
    "#emails_preprocessed = []\n",
    "\n",
    "#for i, body in enumerate(emails_df[\"content_str\"]):\n",
    "    #get sentence level\n",
    "#    sents = nltk.tokenize.sent_tokenize(body)\n",
    "#    canon = []\n",
    "#    proc_body = []\n",
    "#    for sent in sents:\n",
    "        #list of tokens in sentence\n",
    "#        sent_tokens = tokenizer.tokenize(sent.lower())\n",
    "#        canon += utils.canonicalize_words(sent_tokens)\n",
    "#        new_sent = [\"<s>\"]\n",
    "#        for w in canon:\n",
    "#            if w != \",\" and \"--\" not in w and \"@\" not in w and \"http\" not in w:\n",
    "#                new_sent += w\n",
    "        # remove digits\n",
    "#        proc_body += new_sent\n",
    "#    emails_preprocessed.append(proc_body)\n",
    "\n",
    "#emails_df[\"content_tokens\"] = email_tokens\n",
    "#print(\"Total Number of Tokens:\", len(all_tokens))\n",
    "#emails_df[\"content_proc\"] = emails_preprocessed\n",
    "#emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocab\n",
    "# V = size\n",
    "#V = 10000\n",
    "#vocab = vocabulary.Vocabulary(all_tokens, size=V)\n",
    "#vocab = vocabulary.Vocabulary(all_tokens)\n",
    "#print(\"Vocabulary size: {:,}\".format(vocab.size))\n",
    "#vocab_ids = vocab.words_to_ids(all_tokens)\n",
    "#print(\"Unigrams: \", len(vocab.unigram_counts))\n",
    "\n",
    "#emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "      <th>content_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>[here, is, our, forecast, &lt;s&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>[traveling, to, have, a, business, meeting, ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>[test, successful, &lt;s&gt;, way, to, go, !, !, &lt;s&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>[randy, can, you, send, me, a, schedule, of, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>[let, 's, shoot, for, tuesday, at, DGDG:DGDG, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  \\\n",
       "0     allen-p/_sent_mail/1.   \n",
       "1    allen-p/_sent_mail/10.   \n",
       "2   allen-p/_sent_mail/100.   \n",
       "3  allen-p/_sent_mail/1000.   \n",
       "4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
       "\n",
       "                                         content_str  \\\n",
       "0                          Here is our forecast\\n\\n    \n",
       "1  Traveling to have a business meeting takes the...   \n",
       "2                     test successful.  way to go!!!   \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...   \n",
       "4                Let's shoot for Tuesday at 11:45.     \n",
       "\n",
       "                                        content_proc  \n",
       "0                     [here, is, our, forecast, <s>]  \n",
       "1  [traveling, to, have, a, business, meeting, ta...  \n",
       "2  [test, successful, <s>, way, to, go, !, !, <s>...  \n",
       "3  [randy, can, you, send, me, a, schedule, of, t...  \n",
       "4  [let, 's, shoot, for, tuesday, at, DGDG:DGDG, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREPROCESSING STEP\n",
    "# run-time = 30 mins on local machine with FULL dataset\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "# preprocess email bodies with unknowns and sentence buffers\n",
    "emails_preprocessed = []\n",
    "\n",
    "for i, body in enumerate(emails_df[\"content_str\"]):\n",
    "    #get sentence level\n",
    "    sents = nltk.tokenize.sent_tokenize(body.lower())\n",
    "    list_sents = []\n",
    "    canon = []\n",
    "    for sent in sents:\n",
    "        #list of tokens in sentence\n",
    "        sent_tokens = tokenizer.tokenize(sent)\n",
    "        new_sent = []\n",
    "        for w in sent_tokens:\n",
    "            re.sub(\"-\",\"\",w)\n",
    "            if (w!=\",\" and w!=\".\" and \"--\" not in w and \"@\" not in w and \"forwarded\" not in w and \"http\" not in w and \"www.\" not in w):\n",
    "                new_sent += [w]\n",
    "        #canon += utils.canonicalize_words(sent_tokens)\n",
    "        list_sents += utils.canonicalize_words(new_sent)+[\"<s>\"]\n",
    "        #if canon != \",\" and canon != \".\" and \"--\" not in canon and \"@\" not in canon and \"http\" not in canon:\n",
    "            #list_sents += canon+[\"<s>\"]\n",
    "    #preprocessed = list(utils.preprocess_sentences(list_sents, vocab, use_eos=True, emit_ids=False))\n",
    "    #just keep word IDs\n",
    "    #preprocessed = list_sents\n",
    "    emails_preprocessed.append(list_sents)\n",
    "\n",
    "emails_df[\"content_proc\"] = emails_preprocessed\n",
    "#emails_preprocessed[2]\n",
    "#print(emails_df.shape)\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit Length of Emails to 2,000 Preprocessed Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517401, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "      <th>content_proc</th>\n",
       "      <th>content_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>[here, is, our, forecast, &lt;s&gt;]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>[traveling, to, have, a, business, meeting, ta...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>[test, successful, &lt;s&gt;, way, to, go, !, !, &lt;s&gt;...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>[randy, can, you, send, me, a, schedule, of, t...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>[let, 's, shoot, for, tuesday, at, DGDG:DGDG, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  \\\n",
       "0     allen-p/_sent_mail/1.   \n",
       "1    allen-p/_sent_mail/10.   \n",
       "2   allen-p/_sent_mail/100.   \n",
       "3  allen-p/_sent_mail/1000.   \n",
       "4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
       "\n",
       "                                         content_str  \\\n",
       "0                          Here is our forecast\\n\\n    \n",
       "1  Traveling to have a business meeting takes the...   \n",
       "2                     test successful.  way to go!!!   \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...   \n",
       "4                Let's shoot for Tuesday at 11:45.     \n",
       "\n",
       "                                        content_proc  content_length  \n",
       "0                     [here, is, our, forecast, <s>]               5  \n",
       "1  [traveling, to, have, a, business, meeting, ta...             150  \n",
       "2  [test, successful, <s>, way, to, go, !, !, <s>...              11  \n",
       "3  [randy, can, you, send, me, a, schedule, of, t...              39  \n",
       "4  [let, 's, shoot, for, tuesday, at, DGDG:DGDG, ...               8  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final preprocessed strings for feature generation\n",
    "#emails_df[\"content_proc\"] = emails_df[\"content_IDS\"].apply(lambda x: ' '.join(vocab.ids_to_words(x)))\n",
    "# email length feature\n",
    "print(emails_df.shape)\n",
    "emails_df[\"content_length\"] = emails_df[\"content_proc\"].apply(len)\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323047     41737\n",
      "74321      42784\n",
      "58523      42784\n",
      "59058      44690\n",
      "73895      44690\n",
      "323051     44711\n",
      "323616     45325\n",
      "58238      45872\n",
      "74539      45872\n",
      "260177     47647\n",
      "368235     49317\n",
      "323166     50611\n",
      "323180     51851\n",
      "323620     53811\n",
      "56264      54368\n",
      "75868      54368\n",
      "323068     60536\n",
      "323624     69620\n",
      "365604    210253\n",
      "114312    247974\n",
      "Name: content_length, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95f699d6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_20 = np.argsort(emails_df[\"content_length\"]).tail(20)\n",
    "print(emails_df[\"content_length\"][top_20])\n",
    "plt.hist(np.array(emails_df[\"content_length\"]), bins=30, range=(0,5000))\n",
    "plt.title(\"Email Body Length Distribution\")\n",
    "plt.xlabel(\"Doc Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "      <th>content_proc</th>\n",
       "      <th>content_length</th>\n",
       "      <th>email_list</th>\n",
       "      <th>email_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>[here, is, our, forecast, &lt;s&gt;]</td>\n",
       "      <td>5</td>\n",
       "      <td>[here, is, our, forecast, &lt;s&gt;]</td>\n",
       "      <td>here is our forecast &lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>[traveling, to, have, a, business, meeting, ta...</td>\n",
       "      <td>150</td>\n",
       "      <td>[traveling, to, have, a, business, meeting, ta...</td>\n",
       "      <td>traveling to have a business meeting takes the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>[test, successful, &lt;s&gt;, way, to, go, !, !, &lt;s&gt;...</td>\n",
       "      <td>11</td>\n",
       "      <td>[test, successful, &lt;s&gt;, way, to, go, !, !, &lt;s&gt;...</td>\n",
       "      <td>test successful &lt;s&gt; way to go ! ! &lt;s&gt; ! &lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>[randy, can, you, send, me, a, schedule, of, t...</td>\n",
       "      <td>39</td>\n",
       "      <td>[randy, can, you, send, me, a, schedule, of, t...</td>\n",
       "      <td>randy can you send me a schedule of the salary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>[let, 's, shoot, for, tuesday, at, DGDG:DGDG, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>[let, 's, shoot, for, tuesday, at, DGDG:DGDG, ...</td>\n",
       "      <td>let 's shoot for tuesday at DGDG:DGDG &lt;s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  \\\n",
       "0     allen-p/_sent_mail/1.   \n",
       "1    allen-p/_sent_mail/10.   \n",
       "2   allen-p/_sent_mail/100.   \n",
       "3  allen-p/_sent_mail/1000.   \n",
       "4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
       "\n",
       "                                         content_str  \\\n",
       "0                          Here is our forecast\\n\\n    \n",
       "1  Traveling to have a business meeting takes the...   \n",
       "2                     test successful.  way to go!!!   \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...   \n",
       "4                Let's shoot for Tuesday at 11:45.     \n",
       "\n",
       "                                        content_proc  content_length  \\\n",
       "0                     [here, is, our, forecast, <s>]               5   \n",
       "1  [traveling, to, have, a, business, meeting, ta...             150   \n",
       "2  [test, successful, <s>, way, to, go, !, !, <s>...              11   \n",
       "3  [randy, can, you, send, me, a, schedule, of, t...              39   \n",
       "4  [let, 's, shoot, for, tuesday, at, DGDG:DGDG, ...               8   \n",
       "\n",
       "                                          email_list  \\\n",
       "0                     [here, is, our, forecast, <s>]   \n",
       "1  [traveling, to, have, a, business, meeting, ta...   \n",
       "2  [test, successful, <s>, way, to, go, !, !, <s>...   \n",
       "3  [randy, can, you, send, me, a, schedule, of, t...   \n",
       "4  [let, 's, shoot, for, tuesday, at, DGDG:DGDG, ...   \n",
       "\n",
       "                                           email_str  \n",
       "0                           here is our forecast <s>  \n",
       "1  traveling to have a business meeting takes the...  \n",
       "2        test successful <s> way to go ! ! <s> ! <s>  \n",
       "3  randy can you send me a schedule of the salary...  \n",
       "4          let 's shoot for tuesday at DGDG:DGDG <s>  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#takes about 10 minutes\n",
    "max_len = 2500\n",
    "emails_df[\"email_list\"] = emails_df[\"content_proc\"].apply(lambda x: x[0:min(len(x), max_len)])\n",
    "emails_df[\"email_str\"] = emails_df[\"email_list\"].apply(lambda x: ' '.join(x))\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Raw Contents for Suspicious Phrases\n",
    "### Targeted Heuristics with Phrase Searches\n",
    "Use this block to search raw messages and store the row indexes in *target_ids*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7)\n",
      "Matching indexes: [1332, 3054, 3947, 3949]\n"
     ]
    }
   ],
   "source": [
    "# test phrase - enter between quotes\n",
    "phrase = \"fraud\"\n",
    "\n",
    "query = emails_df[emails_df['email_str'].str.contains(phrase, case=False)]\n",
    "print(query.shape)\n",
    "print(\"Matching indexes:\", query.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remind jim how the h/j/k spread acted this year.  granted it won't behave \n",
      "that way again until close to expiry, but i like the j/k outright much moreso \n",
      "than the condor.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Caroline Abramo@ENRON\n",
      "04/30/2001 12:24 PM\n",
      "To: John Arnold/HOU/ECT@ECT\n",
      "cc:  \n",
      "Subject: pulaski\n",
      "\n",
      "\n",
      "---------------------- Forwarded by Caroline Abramo/Corp/Enron on 04/30/2001 \n",
      "01:23 PM ---------------------------\n",
      "\n",
      "\n",
      "Jim Pulaski <Jim.Pulaski@tudor.com> on 04/30/2001 12:17:09 PM\n",
      "To: \"Caroline. Abramo (E-mail)\" <Caroline.Abramo@enron.com>\n",
      "cc:  \n",
      "\n",
      "Subject: \n",
      "\n",
      "\n",
      "btw,  that wasnt me buying the f-g/j-k on friday at 4\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# enter matching index from list above\n",
    "enter_id = 3443\n",
    "print(query.loc[enter_id,'content_str'])\n",
    "\n",
    "# store ids here in the form {123: 1, 456: 1, ...}\n",
    "target_dict = {16212: 1, 450200: 1, 114757: 1, 373: 1, 346: 1, 405: 1, 27091: 1, 13966: 1, 8861: 1, 92183: 1, 17932: 1, 12955: 1, 8101: 1, 19004: 1,\n",
    "              32643: 1, 511: 1, 908: 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review a Random Sample for Labeling\n",
    "\n",
    "200 examples from first 50,000 emails in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample set shape: (200, 3)\n"
     ]
    }
   ],
   "source": [
    "# keep seed = 24 for sample of first 50000 emails\n",
    "random.seed(24)\n",
    "rand_num = 100\n",
    "rand_ids_1 = random.sample(range(2000), rand_num)\n",
    "rand_ids_2 = random.sample(range(2000,50000), rand_num)\n",
    "rand_ids = rand_ids_1 + rand_ids_2\n",
    "rand_set = emails_df.loc[rand_ids,]\n",
    "#print(rand_ids)\n",
    "print(\"Sample set shape:\", rand_set.shape)\n",
    "#for id_ in rand_ids:\n",
    "#    print(id_)\n",
    "#    print(rand_set.loc[id_, 'content_str'])\n",
    "\n",
    "# assign labels based on id\n",
    "label_dict = {373: 1, 346: 1, 405: 1, 27091: 1, 13966: 1}\n",
    "rand_set[\"suspicious_ind\"] = np.zeros(len(rand_ids))\n",
    "for k in label_dict.keys():\n",
    "    rand_set.loc[k, \"suspicious_ind\"] = label_dict.get(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "      <th>suspicious_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>allen-p/deleted_items/381.</td>\n",
       "      <td>Message-ID: &lt;26393700.1075862162007.JavaMail.e...</td>\n",
       "      <td>[IMAGE]\\n [IMAGE][IMAGE]       [IMAGE] Yahoo! ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>allen-p/all_documents/266.</td>\n",
       "      <td>Message-ID: &lt;16945.1075855671306.JavaMail.evan...</td>\n",
       "      <td>Kay &amp; Neal,\\n\\nThanks for remembering my birth...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>allen-p/discussion_threads/212.</td>\n",
       "      <td>Message-ID: &lt;19120705.1075855677934.JavaMail.e...</td>\n",
       "      <td>Attached  are two files that illustrate the fo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>allen-p/all_documents/73.</td>\n",
       "      <td>Message-ID: &lt;22565759.1075855667097.JavaMail.e...</td>\n",
       "      <td>Put me down as a reviewer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>allen-p/_sent_mail/439.</td>\n",
       "      <td>Message-ID: &lt;14134673.1075855725697.JavaMail.e...</td>\n",
       "      <td>Jacques,\\n\\nStill trying to close the loop on ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file  \\\n",
       "1458       allen-p/deleted_items/381.   \n",
       "784        allen-p/all_documents/266.   \n",
       "1719  allen-p/discussion_threads/212.   \n",
       "1193        allen-p/all_documents/73.   \n",
       "373           allen-p/_sent_mail/439.   \n",
       "\n",
       "                                                message  \\\n",
       "1458  Message-ID: <26393700.1075862162007.JavaMail.e...   \n",
       "784   Message-ID: <16945.1075855671306.JavaMail.evan...   \n",
       "1719  Message-ID: <19120705.1075855677934.JavaMail.e...   \n",
       "1193  Message-ID: <22565759.1075855667097.JavaMail.e...   \n",
       "373   Message-ID: <14134673.1075855725697.JavaMail.e...   \n",
       "\n",
       "                                            content_str  suspicious_ind  \n",
       "1458  [IMAGE]\\n [IMAGE][IMAGE]       [IMAGE] Yahoo! ...             0.0  \n",
       "784   Kay & Neal,\\n\\nThanks for remembering my birth...             0.0  \n",
       "1719  Attached  are two files that illustrate the fo...             0.0  \n",
       "1193                          Put me down as a reviewer             0.0  \n",
       "373   Jacques,\\n\\nStill trying to close the loop on ...             1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules-Based Labeling from Other Enron Email Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate BOW features and longer N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW shape:  (50000, 5000)\n",
      "BOW TF-IDF: (50000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# generate BOW features based on vocab.size V (above) and transform to TF-IDF\n",
    "# uses canonicalized words\n",
    "#bow_feats = utils.id_lists_to_sparse_bow(emails_df[\"content_IDS\"], vocab.size)\n",
    "#print(\"BOW shape: \", bow_feats.shape)\n",
    "#transformer = TfidfTransformer()\n",
    "#bow_tfidf = transformer.fit_transform(bow_feats)\n",
    "#print(\"BOW TF-IDF:\", bow_tfidf.shape)\n",
    "\n",
    "# TOO MANY ODD TOKENS CAPTURED BY VOCAB OBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-grams shape:  (50000, 75864)\n",
      "N-grams TF-IDF: (50000, 75864)\n"
     ]
    }
   ],
   "source": [
    "# consider longer n-grams\n",
    "transformer = TfidfTransformer()\n",
    "vectorize = CountVectorizer(ngram_range=(1, 2), max_df=.1, min_df=20)\n",
    "n_grams = vectorize.fit_transform(emails_df[\"content_proc\"])\n",
    "print(\"N-grams shape: \", n_grams.shape)\n",
    "\n",
    "n_grams_idf = transformer.fit_transform(n_grams)\n",
    "print(\"N-grams TF-IDF:\", n_grams_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 75864)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join features\n",
    "length_sparse = sparse.csr_matrix(emails_df[\"email_length\"]).transpose()\n",
    "# with length feature\n",
    "#feature_vects = sparse.hstack([length_sparse, bow_tfidf, n_grams_idf])\n",
    "#feature_vects = sparse.hstack([bow_tfidf, n_grams_idf])\n",
    "feature_vects = n_grams_idf\n",
    "feature_vects.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit & Evaluate Simple K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=5, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.01, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit k-means (n=4, tol=.01, max_iter=100 takes ~20 mins to train)\n",
    "kmeans = KMeans(n_clusters=5, tol=.01, max_iter=100)\n",
    "kmeans.fit(feature_vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 clusters: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Positive labels:   [2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions on positively labeled examples\n",
    "base_preds = kmeans.predict(feature_vects)\n",
    "print(\"First 30 clusters:\", base_preds[:30])\n",
    "print(\"Positive labels:  \", base_preds[list(label_dict.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 75864)\n"
     ]
    }
   ],
   "source": [
    "# evaluate closest examples in cluster 2 based on cosine similarity\n",
    "suspicious_ids = np.zeros(len(base_preds))\n",
    "for k in label_dict.keys():\n",
    "    suspicious_ids[k] = label_dict.get(k)\n",
    "\n",
    "# enter index of typical cluster\n",
    "key_cluster = 2\n",
    "\n",
    "cluster_ids = (base_preds==key_cluster).astype(int)\n",
    "\n",
    "features_np = sparse.csr_matrix.todense(feature_vects)\n",
    "\n",
    "labeled_feats = features_np[np.multiply(suspicious_ids, cluster_ids).astype(bool)]\n",
    "print(labeled_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([346, 27091, 373, 13966, 405])\n",
      "(5, 50000)\n",
      "[[21177 31738 39744 13961 11650 15532  7014   966   346  2759]\n",
      " [  985  2779  1893  2769   356   976  1879   373  2787   995]\n",
      " [  357   358  1892  2771   978   977  2820  1855   405  1027]\n",
      " [17248 10977 14371 11429 16116 13982 11606 13966  9998 17433]\n",
      " [20382 19225 29563 21933 27092 30259 24055 31124 27091 20569]]\n",
      "0.164362146998\n"
     ]
    }
   ],
   "source": [
    "# cosine_similarity\n",
    "print(label_dict.keys())\n",
    "cos_sims = cosine_similarity(labeled_feats, feature_vects)\n",
    "print(cos_sims.shape)\n",
    "closest = np.argsort(cos_sims, axis = 1)\n",
    "print(closest[:,-10:])\n",
    "print(cos_sims[1,985])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> jacques , the agreement looks fine . </s> <s> my only comment is that george and larry might object to the language that `` the bank that was requested to finance the construction of the project declined to make the loan based on the high costs of the construction of the project '' . </s> <s> <unk> , that bank lowered the loan amount based on lower estimates of <unk> which <unk> the amount of equity that would be required . </s> <s> did i loan them $ DGDGDGDGDGDGDG ? </s> <s> i thought it was less . </s> <s> regarding exhibit a , the assets include : the land , <unk> plans , engineering completed , appraisal , and <unk> study . </s> <s> most of these items are in a state of partial completion by the consultants . </s> <s> i have been speaking directly to the architect , engineer , and <unk> engineer . </s> <s> i am unclear on what is the best way to proceed with these consultants . </s> <s> the obligations should include the fees owed to the consultants above . </s> <s> do we need to list balances due or just list the work completed as an asset and give consideration of $ DGDGDGDG for the cash paid to the engineer and <unk> . </s> <s> phillip </s>\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nearest emails flagged:\n",
    "emails_df.loc[985, \"content_proc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided LDA Topic Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>content_str</th>\n",
       "      <th>content_proc</th>\n",
       "      <th>content_length</th>\n",
       "      <th>email_list</th>\n",
       "      <th>email_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>[here, is, our, forecast, &lt;s&gt;]</td>\n",
       "      <td>5</td>\n",
       "      <td>[here, is, our, forecast, &lt;s&gt;]</td>\n",
       "      <td>here is our forecast &lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>[traveling, to, have, a, business, meeting, ta...</td>\n",
       "      <td>150</td>\n",
       "      <td>[traveling, to, have, a, business, meeting, ta...</td>\n",
       "      <td>traveling to have a business meeting takes the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>[test, successful, &lt;s&gt;, way, to, go, !, !, &lt;s&gt;...</td>\n",
       "      <td>11</td>\n",
       "      <td>[test, successful, &lt;s&gt;, way, to, go, !, !, &lt;s&gt;...</td>\n",
       "      <td>test successful &lt;s&gt; way to go ! ! &lt;s&gt; ! &lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>[randy, can, you, send, me, a, schedule, of, t...</td>\n",
       "      <td>39</td>\n",
       "      <td>[randy, can, you, send, me, a, schedule, of, t...</td>\n",
       "      <td>randy can you send me a schedule of the salary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>[let, 's, shoot, for, tuesday, at, DGDG:DGDG, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>[let, 's, shoot, for, tuesday, at, DGDG:DGDG, ...</td>\n",
       "      <td>let 's shoot for tuesday at DGDG:DGDG &lt;s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  \\\n",
       "0     allen-p/_sent_mail/1.   \n",
       "1    allen-p/_sent_mail/10.   \n",
       "2   allen-p/_sent_mail/100.   \n",
       "3  allen-p/_sent_mail/1000.   \n",
       "4  allen-p/_sent_mail/1001.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...   \n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...   \n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
       "\n",
       "                                         content_str  \\\n",
       "0                          Here is our forecast\\n\\n    \n",
       "1  Traveling to have a business meeting takes the...   \n",
       "2                     test successful.  way to go!!!   \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...   \n",
       "4                Let's shoot for Tuesday at 11:45.     \n",
       "\n",
       "                                        content_proc  content_length  \\\n",
       "0                     [here, is, our, forecast, <s>]               5   \n",
       "1  [traveling, to, have, a, business, meeting, ta...             150   \n",
       "2  [test, successful, <s>, way, to, go, !, !, <s>...              11   \n",
       "3  [randy, can, you, send, me, a, schedule, of, t...              39   \n",
       "4  [let, 's, shoot, for, tuesday, at, DGDG:DGDG, ...               8   \n",
       "\n",
       "                                          email_list  \\\n",
       "0                     [here, is, our, forecast, <s>]   \n",
       "1  [traveling, to, have, a, business, meeting, ta...   \n",
       "2  [test, successful, <s>, way, to, go, !, !, <s>...   \n",
       "3  [randy, can, you, send, me, a, schedule, of, t...   \n",
       "4  [let, 's, shoot, for, tuesday, at, DGDG:DGDG, ...   \n",
       "\n",
       "                                           email_str  \n",
       "0                           here is our forecast <s>  \n",
       "1  traveling to have a business meeting takes the...  \n",
       "2        test successful <s> way to go ! ! <s> ! <s>  \n",
       "3  randy can you send me a schedule of the salary...  \n",
       "4          let 's shoot for tuesday at DGDG:DGDG <s>  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "(500000, 2000)\n"
     ]
    }
   ],
   "source": [
    "#Implement LDA for topics of each document\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "#n_samples = 2000\n",
    "n_features = 2000\n",
    "n_components = 10\n",
    "n_top_words = 20\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "random.seed(24)\n",
    "samples = 500000\n",
    "rand_ids = random.sample(range(emails_df.shape[0]), samples)\n",
    "email_samples = emails_df.loc[rand_ids,]\n",
    "\n",
    "train_content = list(email_samples['email_str'])\n",
    "#dev_content = list(email_samples['content_str'])\n",
    "\n",
    "#tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "#                                   max_features=n_features,\n",
    "#                                   stop_words='english')\n",
    "\n",
    "#tfidf = tfidf_vectorizer.fit_transform(all_content)\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.6, min_df=10,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english',\n",
    "                                ngram_range = (1,1))\n",
    "#t0 = time()\n",
    "#tf = tf_vectorizer.fit_transform(data_samples)\n",
    "#print(\"done in %0.3fs.\" % (time() - t0))\n",
    "#print()\n",
    "\n",
    "tf_train = tf_vectorizer.fit_transform(train_content)\n",
    "tf_vocab = tf_vectorizer.vocabulary_\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print(tf_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_features=2000...\n",
      "done in 190.654s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: dg gas dgdgdgdgdgdg deal dgdgdgdgdg dgdgdg price day market contract deals capacity month rate term daily total order pipeline ferc\n",
      "Topic #1: dgdgdg dg pm database fax scheduled dgdgdgdgdg error sat outages contact london ct time phone fri dbcaps97data pt sun outage\n",
      "Topic #2: image dg com day new way free just time dgdgdg like click home houston mail great travel ll good week\n",
      "Topic #3: power energy california said market company enron state dg new million gas electricity year prices companies utilities price commission markets\n",
      "Topic #4: enron information dg business new access report management time services group email questions risk available contact site following process team\n",
      "Topic #5: dg font td br size tr width com align fantasy dgdgdg updated href face table gif sportsline league border height\n",
      "Topic #6: com enron mail dg message subject doc dgdgdg kay mailto net intended aol pm mann recipient sent final file ca\n",
      "Topic #7: ect enron hou ees corp cc na pm subject enron_development enronxgate et lon communications mark david john mary pdx richard\n",
      "Topic #8: 20 3d enron dgdgdg agreement 01 sara credit 09 legal trading ena houston shackleton america master corp north isda transactions\n",
      "Topic #9: subject know thanks sent pm message dg original let cc need meeting like think vince jeff time just john monday\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_features=%d...\"\n",
    "      % (n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf_train)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "print_top_words(lda, tf_feature_names, n_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'raptor' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-94f84fc9f5ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_feature_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raptor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: 'raptor' is not in list"
     ]
    }
   ],
   "source": [
    "tf_feature_names.index('raptor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'raptor' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-64fc12914124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_topic_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mseed_topics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf_feature_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'raptor' is not in list"
     ]
    }
   ],
   "source": [
    "import lda\n",
    "import guidedlda\n",
    "\n",
    "seed_topic_list = [['raptor','condor','assets','swap','trutta','jedi','whitewing','hawaii']]\n",
    "seed_topics = {}\n",
    "for t_id, keywords in enumerate(seed_topic_list):\n",
    "    for word in keywords:\n",
    "        seed_topics[tf_feature_names.index(word)] = t_id\n",
    "\n",
    "t0 = time()\n",
    "glda = guidedlda.GuidedLDA(n_topics = 10, n_iter = 5, random_state = 1, refresh = 20)\n",
    "glda.fit(tf_train, seed_topics = seed_topics, seed_confidence = 0.9)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "topic_word = glda.topic_word_\n",
    "n_top_words = 10\n",
    "print(topic_word.shape)\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(tf_feature_names)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
